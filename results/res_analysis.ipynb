{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0288006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13a59f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "try : \n",
    "    linear_results_path = 'results_linear.csv'\n",
    "    df_linear = pd.read_csv(linear_results_path)\n",
    "    df_linear = df_linear.drop(columns='Unnamed: 0')\n",
    "except Exception as e:\n",
    "    print('Linear results not found')\n",
    "try:\n",
    "    graph_results_path = 'results_graph.csv'\n",
    "    df_graph = pd.read_csv(graph_results_path)\n",
    "    df_graph = df_graph.drop(columns='Unnamed: 0')\n",
    "except Exception as e:\n",
    "    print('Graph Results not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e6786",
   "metadata": {},
   "source": [
    "Top performing Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eca53e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear_sort_acc = df_linear.sort_values(by='Test Accuracy',ascending=False)\n",
    "df_linear_sort_f1 = df_linear.sort_values(by='Test F1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0a32838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing linear models in terms of Accuracy\n",
      "             model    model_name  Test Accuracy   Test F1  max_depth  \\\n",
      "3863  RandomForest  RandomForest       0.443878  0.238329       10.0   \n",
      "3860  RandomForest  RandomForest       0.443878  0.238557       10.0   \n",
      "3820  RandomForest  RandomForest       0.438776  0.238391       20.0   \n",
      "3870  RandomForest  RandomForest       0.438776  0.229576       10.0   \n",
      "3926  RandomForest  RandomForest       0.438776  0.248739       10.0   \n",
      "\n",
      "      min_samples_split  min_samples_leaf max_features  n_estimators bootstrap  \n",
      "3863                5.0               1.0         log2         500.0      True  \n",
      "3860                5.0               1.0         sqrt         500.0      True  \n",
      "3820               10.0               1.0         sqrt         300.0      True  \n",
      "3870               10.0               1.0         log2         500.0      True  \n",
      "3926                5.0               1.0         log2         800.0      True  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Best performing linear models in terms of Accuracy\")\n",
    "best_acc_mod = df_linear_sort_acc.head(n=5)\n",
    "best_acc_mod = best_acc_mod.dropna(axis=1)\n",
    "print(best_acc_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c706250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing linear models in terms of F1 score\n",
      "             model    model_name  Test Accuracy   Test F1  min_samples_split  \\\n",
      "3893  RandomForest  RandomForest       0.423469  0.288819                5.0   \n",
      "3466  DecisionTree  DecisionTree       0.387755  0.285646                5.0   \n",
      "3467  DecisionTree  DecisionTree       0.387755  0.284462                5.0   \n",
      "3458  DecisionTree  DecisionTree       0.382653  0.282324                5.0   \n",
      "3574  DecisionTree  DecisionTree       0.357143  0.280146                5.0   \n",
      "\n",
      "      min_samples_leaf  \n",
      "3893               1.0  \n",
      "3466               1.0  \n",
      "3467               1.0  \n",
      "3458               1.0  \n",
      "3574               1.0  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Best performing linear models in terms of F1 score\")\n",
    "best_f1_mod = df_linear_sort_f1.head(n=5)\n",
    "best_f1_mod = best_f1_mod.dropna(axis=1)\n",
    "print(best_f1_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3211e30",
   "metadata": {},
   "source": [
    "Best parameters per each linear model category (by F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e257d477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'MLP', 'lr': 0.005, 'n_epochs': 500.0, 'hidden_size': 128.0, 'weight_decay': 0.001, 'batch_size': 128.0, 'activation': 'leaky_relu', 'dropout': 0.4, 'model_name': 'MLP', 'Test Accuracy': 0.4285714285714285, 'Test F1': 0.2166967044646196}\n",
      "{'model': 'DecisionTree', 'model_name': 'DecisionTree', 'Test Accuracy': 0.3877551020408163, 'Test F1': 0.2856455729469105, 'max_depth': 7.0, 'min_samples_split': 5.0, 'min_samples_leaf': 1.0, 'criterion': 'entropy'}\n",
      "{'model': 'RandomForest', 'model_name': 'RandomForest', 'Test Accuracy': 0.423469387755102, 'Test F1': 0.2888190619833604, 'min_samples_split': 5.0, 'min_samples_leaf': 1.0, 'max_features': 'sqrt', 'n_estimators': 500.0, 'bootstrap': True}\n",
      "{'model': 'Logreg', 'model_name': 'Logreg', 'Test Accuracy': 0.4336734693877551, 'Test F1': 0.2418759988078755, 'C': 5.0, 'penalty': 'l2', 'solver': 'saga', 'max_iter': 1000.0, 'fit_intercept': True, 'tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "models = df_linear['model_name'].unique()\n",
    "for linear_model in models:\n",
    "    df_model = df_linear[df_linear['model_name'] == linear_model]\n",
    "    df_model = df_model.dropna(axis=1)\n",
    "    df_model = df_model.sort_values(by='Test F1',ascending=False)\n",
    "    best_model = df_model.head(n=1)\n",
    "    print(best_model.iloc[0].to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138c9d1",
   "metadata": {},
   "source": [
    "Top performing Graph Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ca40d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph_sort_acc = df_graph.sort_values(by='Test Accuracy',ascending=False)\n",
    "df_graph_sort_f1 = df_graph.sort_values(by='Test F1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6249195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing graph models in terms of Accuracy\n",
      "    model  hidden_size     lr  n_epochs  embed_dim model_name  Test Accuracy  \\\n",
      "104   GAT          512  0.001       100         16        GAT       0.413265   \n",
      "26    GCN          256  0.005       100         16        GCN       0.408163   \n",
      "33    GCN          256  0.001       100         32        GCN       0.403061   \n",
      "5     GCN          128  0.010       200         32        GCN       0.403061   \n",
      "57    GAT          128  0.010       100         32        GAT       0.403061   \n",
      "\n",
      "      Test F1  \n",
      "104  0.178641  \n",
      "26   0.198435  \n",
      "33   0.180472  \n",
      "5    0.199776  \n",
      "57   0.201956  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Best performing graph models in terms of Accuracy\")\n",
    "best_acc_mod = df_graph_sort_acc.head(n=5)\n",
    "best_acc_mod = best_acc_mod.dropna(axis=1)\n",
    "print(best_acc_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c206cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing graph models in terms of F1 score\n",
      "   model  hidden_size     lr  n_epochs  embed_dim model_name  Test Accuracy  \\\n",
      "99   GAT          512  0.005       100         32        GAT       0.397959   \n",
      "34   GCN          256  0.001       200         16        GCN       0.382653   \n",
      "83   GAT          256  0.005       200         32        GAT       0.382653   \n",
      "53   GCN          512  0.001       200         32        GCN       0.397959   \n",
      "59   GAT          128  0.010       200         32        GAT       0.367347   \n",
      "\n",
      "     Test F1  \n",
      "99  0.215046  \n",
      "34  0.213082  \n",
      "83  0.207277  \n",
      "53  0.207182  \n",
      "59  0.206280  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Best performing graph models in terms of F1 score\")\n",
    "best_f1_mod = df_graph_sort_f1.head(n=5)\n",
    "best_f1_mod = best_f1_mod.dropna(axis=1)\n",
    "print(best_f1_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5352b40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'GCN', 'hidden_size': 256, 'lr': 0.001, 'n_epochs': 200, 'embed_dim': 16, 'model_name': 'GCN', 'Test Accuracy': 0.3826530612244898, 'Test F1': 0.2130822586500393}\n",
      "{'model': 'GAT', 'hidden_size': 512, 'lr': 0.005, 'n_epochs': 100, 'embed_dim': 32, 'model_name': 'GAT', 'Test Accuracy': 0.3979591836734694, 'Test F1': 0.2150455452207561}\n"
     ]
    }
   ],
   "source": [
    "models = df_graph['model_name'].unique()\n",
    "for linear_model in models:\n",
    "    df_model = df_graph[df_graph['model_name'] == linear_model]\n",
    "    df_model = df_model.dropna(axis=1)\n",
    "    df_model = df_model.sort_values(by='Test F1',ascending=False)\n",
    "    best_model = df_model.head(n=1)\n",
    "    print(best_model.iloc[0].to_dict()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
